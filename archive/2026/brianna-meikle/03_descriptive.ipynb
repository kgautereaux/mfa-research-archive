{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cell-frontmatter",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Heart Rate During the Mock Audition\"\n",
    "author: \"Brianna Meikle\"\n",
    "date: \"2026-02-28\"\n",
    "categories:\n",
    "  - performance-anxiety\n",
    "  - heart-rate\n",
    "  - descriptive\n",
    "  - MFA-2026\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": "This analysis presents the heart rate data from five mock audition sessions. Each singer performed two songs — one prepared, one assigned 24 hours in advance — for a three-person faculty panel. All subjects wore Polar H10 heart rate monitors. HR was recorded at 1 Hz (one value per second) and aligned to audio using a clap-based sync point.\n\n**Participants:**\n\n- Singer 1 (S1, M)\n- Singer 2 (S2, F)\n- Singer 3 (S3, F)\n- Singer 4 (S4, F)\n- Singer 5 (S5, M)\n- Panelist 1 (F1) — HR data available for all 5 sessions\n- Panelist 2 (F2) — HR data available for all 5 sessions\n- Panelist 3 (F3) — HR data available for all 5 sessions\n\n**Assigned pieces:** Female singers (S2, S3, S4): \"If You Knew My Story\" | Male singers (S1, S5): \"Shiksa Goddess\"\n\n**Data constraint:** HR was exported from Polar Flow at 1 Hz — averaged BPM per second, not beat-to-beat RR intervals. Standard HRV metrics cannot be computed. Analysis focuses on HR magnitude, reactivity, and interpersonal synchrony.\n\n**Methodological notes:**\n- All faculty panelists were seated throughout all auditions. No standing, walking, or postural changes occurred. All panelist HR variations reflect genuine autonomic responses, not movement artifacts.\n- Panelist 1 wore a facial mask for the duration of the experiment to avoid sharing or receiving illness. This may have contributed slightly to Panelist 1's elevated baseline HR (~100 bpm), though the consistency across all five sessions suggests a stable individual difference rather than a masking artifact."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Load data\n",
    "hr = pd.read_csv('data/aligned_hr.csv')\n",
    "phase_sum = pd.read_csv('data/phase_summaries.csv')\n",
    "\n",
    "singer_names = {\n",
    "    'S1': 'S1 (M)', 'S2': 'S2 (F)', 'S3': 'S3 (F)',\n",
    "    'S4': 'S4 (F)', 'S5': 'S5 (M)'\n",
    "}\n",
    "\n",
    "phase_order = ['pre_singing', 'song_1', 'inter_song_gap', 'song_2', 'post_session']\n",
    "phase_labels = {\n",
    "    'pre_singing': 'Pre-Singing', 'song_1': 'Song 1 (Prepared)',\n",
    "    'inter_song_gap': 'Inter-Song Gap', 'song_2': 'Song 2 (Assigned)',\n",
    "    'post_session': 'Post-Session'\n",
    "}\n",
    "phase_colors = {\n",
    "    'pre_singing': 'rgba(255, 193, 7, 0.15)',\n",
    "    'song_1': 'rgba(76, 175, 80, 0.15)',\n",
    "    'inter_song_gap': 'rgba(158, 158, 158, 0.15)',\n",
    "    'song_2': 'rgba(33, 150, 243, 0.15)',\n",
    "    'post_session': 'rgba(244, 67, 54, 0.15)'\n",
    "}\n",
    "\n",
    "trace_colors = {\n",
    "    'singer': '#e74c3c',\n",
    "    'F1': '#8e44ad',\n",
    "    'F2': '#2ecc71',\n",
    "    'F3': '#2980b9'\n",
    "}\n",
    "\n",
    "singer_colors = {\n",
    "    'S1': '#e74c3c', 'S2': '#e67e22', 'S3': '#27ae60',\n",
    "    'S4': '#3498db', 'S5': '#8e44ad'\n",
    "}\n",
    "\n",
    "panelists = ['F1', 'F2', 'F3']\n",
    "panelist_names = {'F1': 'Panelist 1', 'F2': 'Panelist 2', 'F3': 'Panelist 3'}\n",
    "singers = ['S1', 'S2', 'S3', 'S4', 'S5']\n",
    "perf_phases = ['pre_singing', 'song_1', 'inter_song_gap', 'song_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "def make_session_figure(session_id, singer_label):\n",
    "    sess = hr[hr['session'] == session_id]\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for phase in phase_order:\n",
    "        phase_data = sess[sess['phase'] == phase]\n",
    "        if len(phase_data) == 0:\n",
    "            continue\n",
    "        x0 = phase_data['elapsed_s'].min()\n",
    "        x1 = phase_data['elapsed_s'].max()\n",
    "        fig.add_vrect(\n",
    "            x0=x0, x1=x1, fillcolor=phase_colors[phase],\n",
    "            layer='below', line_width=0,\n",
    "            annotation_text=phase_labels[phase],\n",
    "            annotation_position='top left',\n",
    "            annotation_font_size=10, annotation_font_color='#666'\n",
    "        )\n",
    "    \n",
    "    singer_data = sess[sess['subject'] == session_id]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=singer_data['elapsed_s'], y=singer_data['hr_bpm'],\n",
    "        mode='lines', name=singer_label,\n",
    "        line=dict(color=trace_colors['singer'], width=2),\n",
    "        hovertemplate='%{y} bpm<extra>' + singer_label + '</extra>'\n",
    "    ))\n",
    "    \n",
    "    for pan in panelists:\n",
    "        pan_data = sess[sess['subject'] == pan]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=pan_data['elapsed_s'], y=pan_data['hr_bpm'],\n",
    "            mode='lines', name=panelist_names[pan],\n",
    "            line=dict(color=trace_colors[pan], width=1.5),\n",
    "            hovertemplate='%{y} bpm<extra>' + panelist_names[pan] + '</extra>'\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(text=f'Session {session_id[-1]} \\u2014 {singer_label}', font_size=16),\n",
    "        xaxis_title='Elapsed Time (seconds)',\n",
    "        yaxis_title='Heart Rate (bpm)',\n",
    "        hovermode='x unified', template='plotly_white', height=400,\n",
    "        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "        margin=dict(t=80, b=60)\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part1-header",
   "metadata": {},
   "source": [
    "## Part 1: Individual Session Time Series\n",
    "\n",
    "Each figure shows one audition session with the singer's HR (red) overlaid with Panelist 1 (purple), Panelist 2 (green), and Panelist 3 (blue). Shaded bands indicate audition phases.\n",
    "\n",
    "**Panelist baseline context:** The three panelists — all seated throughout — show a stable hierarchy across all sessions: Panelist 1 runs highest (~98\\u2013108 bpm), Panelist 3 is moderate (~75\\u201395 bpm), and Panelist 2 is lowest (~55\\u201365 bpm). Panelist 2's HR is essentially resting heart rate for a seated adult. These individual differences in resting autonomic tone are consistent across all five sessions, suggesting stable trait-level variation rather than differential responses to specific singers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-text",
   "metadata": {},
   "source": [
    "### Session 1 \\u2014 Singer 1 (M)\n",
    "\n",
    "Singer 1 begins around 127 bpm and ramps steadily upward through song 1 (prepared piece), reaching peaks near 160 bpm. There is a brief dip during the inter-song gap, followed by a sharp rise into song 2 (assigned piece), where HR reaches its highest sustained values (~155\\u2013158 bpm). The three panelists hold flat: Panelist 1 around 100\\u2013108 bpm, Panelist 3 at 85\\u201395 bpm, and Panelist 2 near 58 bpm. The singer's activation gap above the panelist mean is ~60\\u201370 bpm during performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s1-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "make_session_figure('S1', singer_names['S1']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-text",
   "metadata": {},
   "source": [
    "### Session 2 \\u2014 Singer 2 (F)\n",
    "\n",
    "Singer 2 shows the steepest ramp-up of any singer \\u2014 HR climbs from ~120 bpm at the start to peak near 169 bpm during song 1 (prepared). HR drops modestly during the inter-song gap (~145 bpm) but rebounds during song 2 (assigned), reaching ~155 bpm. Panelist 1 drifts from 108 down to ~100 bpm; Panelist 3 hovers in the 75\\u201390 bpm range; Panelist 2 holds steady near 57 bpm. The activation gap widens as the session progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "make_session_figure('S2', singer_names['S2']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-text",
   "metadata": {},
   "source": [
    "### Session 3 \\u2014 Singer 3 (F)\n",
    "\n",
    "Singer 3 follows a similar arc to Singer 2 \\u2014 gradual climb through the pre-singing phase, sustained elevation during song 1 (135\\u2013165 bpm), partial recovery in the gap, and a plateau during song 2 (~150\\u2013158 bpm). Panelist 1 is steady around 101\\u2013107 bpm; Panelist 3 is at 80\\u201395 bpm; Panelist 2 stays near 58\\u201360 bpm. The inter-song gap shows a brief but noticeable HR spike in Panelist 3's trace \\u2014 likely anticipatory activation as the panelist prepares for the next performance (see Panelist Anticipatory Activation below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "make_session_figure('S3', singer_names['S3']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-text",
   "metadata": {},
   "source": [
    "### Session 4 \\u2014 Singer 4 (F)\n",
    "\n",
    "Singer 4 is a clear outlier. HR starts around 80\\u201390 bpm in the pre-singing phase \\u2014 within the range typically seen in a *panelist*, not a singer. During song 1, HR rises modestly to ~105\\u2013120 bpm, well below the 140\\u2013170 bpm range seen in other singers. During song 2, HR actually *drops below baseline*, reaching the mid-70s. This is the most visually striking session in the dataset: the singer's trace overlaps with Panelist 1 and Panelist 3, while Panelist 2 runs below all of them. Panelist 1 spikes to ~113 bpm during the inter-song gap \\u2014 the highest F1 variability in any session (sd=5.8). Panelist 3 is similarly variable (sd=8.1 during the gap).\n",
    "\n",
    "**Important context:** Panelist 3 had a pre-existing teaching relationship with Singer 4. This likely explains the reduced anxiety response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "make_session_figure('S4', singer_names['S4']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-text",
   "metadata": {},
   "source": [
    "### Session 5 \\u2014 Singer 5 (M)\n",
    "\n",
    "Singer 5 shows the highest sustained HR of any participant. Starting from a pre-singing baseline of ~135\\u2013140 bpm (already elevated), HR climbs rapidly through song 1 to peaks near 184 bpm. The inter-song gap provides minimal recovery (~165 bpm), and song 2 drives HR to its highest sustained values (~170\\u2013180 bpm). The three panelists form a clear floor: Panelist 1 at 96\\u2013106 bpm, Panelist 3 at 73\\u201385 bpm, Panelist 2 at 54\\u201359 bpm. The widest activation gap in the study occurs here \\u2014 ~91 bpm between singer and the 3-panelist mean during song 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s5-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "make_session_figure('S5', singer_names['S5']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part2-header",
   "metadata": {},
   "source": [
    "## Part 2: Cross-Session Comparisons\n",
    "\n",
    "### Singer HR by Audition Phase\n",
    "\n",
    "The grouped bar chart below shows each singer's mean HR (with standard deviation bars) during the four performance phases. The pattern is consistent across four of five singers: HR is lowest during pre-singing, rises sharply for song 1, dips slightly during the inter-song gap, and remains elevated or continues rising into song 2. Singer 4 is the exception \\u2014 her HR stays in the 88\\u2013106 bpm range across all phases, never approaching the 140+ bpm levels seen in the others.\n",
    "\n",
    "**Key observation:** Pre-singing baseline HR is remarkably similar across Singers 1, 2, 3, and 5 (~126\\u2013143 bpm), suggesting comparable levels of anticipatory anxiety before singing begins. Singer 4's pre-singing HR (~91 bpm) is 35\\u201350 bpm lower than the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-phase-bar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "phase_bar_colors = {\n",
    "    'pre_singing': '#FFC107', 'song_1': '#4CAF50',\n",
    "    'inter_song_gap': '#9E9E9E', 'song_2': '#2196F3'\n",
    "}\n",
    "\n",
    "fig_phase = go.Figure()\n",
    "for phase in perf_phases:\n",
    "    means, sds, labels = [], [], []\n",
    "    for s in singers:\n",
    "        row = phase_sum[(phase_sum['session'] == s) & (phase_sum['subject'] == s) & (phase_sum['phase'] == phase)]\n",
    "        means.append(row['mean_hr'].values[0] if len(row) > 0 else 0)\n",
    "        sds.append(row['sd_hr'].values[0] if len(row) > 0 else 0)\n",
    "        labels.append(singer_names[s])\n",
    "    fig_phase.add_trace(go.Bar(\n",
    "        name=phase_labels[phase], x=labels, y=means,\n",
    "        error_y=dict(type='data', array=sds, visible=True),\n",
    "        marker_color=phase_bar_colors[phase],\n",
    "        hovertemplate='%{y:.1f} \\u00b1 %{error_y.array:.1f} bpm<extra>' + phase_labels[phase] + '</extra>'\n",
    "    ))\n",
    "fig_phase.update_layout(\n",
    "    title=dict(text='Singer Mean HR by Audition Phase', font_size=16),\n",
    "    xaxis_title='Singer', yaxis_title='Heart Rate (bpm)',\n",
    "    barmode='group', template='plotly_white', height=450,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "fig_phase.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-gap-text",
   "metadata": {},
   "source": [
    "### Singer\\u2013Panelist Activation Gap\n",
    "\n",
    "The chart below quantifies the HR difference between each singer and the mean of all three panelists for each phase. The gap reflects how far the singer's autonomic activation exceeds the panelists' \\u2014 a rough index of the anxiety asymmetry in the audition relationship. With Panelist 2 included (mean HR ~58 bpm, seated), the 3-panelist average is lower than the earlier 2-panelist estimate, so activation gaps are wider.\n",
    "\n",
    "Singers 1, 2, 3, and 5 show gaps of 38\\u201391 bpm, widening as the session progresses. The gap is largest during the inter-song gap and song 2 for most singers \\u2014 suggesting that the stress of performing the assigned piece (less familiar, less rehearsed) compounds the already elevated state from song 1.\n",
    "\n",
    "Singer 4's gap is small but positive (+8 bpm during song 2) \\u2014 her HR stays close to the panelist range. This is the only singer whose physiological state approximates the panelists'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gap-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "fig_gap = go.Figure()\n",
    "for s in singers:\n",
    "    gaps = []\n",
    "    for phase in perf_phases:\n",
    "        singer_row = phase_sum[(phase_sum['session'] == s) & (phase_sum['subject'] == s) & (phase_sum['phase'] == phase)]\n",
    "        pan_rows = phase_sum[(phase_sum['session'] == s) & (phase_sum['subject'].isin(panelists)) & (phase_sum['phase'] == phase)]\n",
    "        if len(singer_row) > 0 and len(pan_rows) == 3:\n",
    "            gaps.append(singer_row['mean_hr'].values[0] - pan_rows['mean_hr'].mean())\n",
    "        else:\n",
    "            gaps.append(0)\n",
    "    fig_gap.add_trace(go.Bar(\n",
    "        name=singer_names[s], x=[phase_labels[p] for p in perf_phases], y=gaps,\n",
    "        marker_color=singer_colors[s],\n",
    "        hovertemplate='%{y:+.1f} bpm<extra>' + singer_names[s] + '</extra>'\n",
    "    ))\n",
    "fig_gap.add_hline(y=0, line_dash='dash', line_color='black', line_width=1)\n",
    "fig_gap.update_layout(\n",
    "    title=dict(text='Singer\\u2013Panelist Activation Gap by Phase (3-Panelist Mean)', font_size=16),\n",
    "    xaxis_title='Phase', yaxis_title='HR Gap (singer \\u2212 panelist mean, bpm)',\n",
    "    barmode='group', template='plotly_white', height=450,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "fig_gap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-reactivity-text",
   "metadata": {},
   "source": [
    "### HR Reactivity Profiles\n",
    "\n",
    "The dot-and-line plot below connects each singer's mean HR across the four phases, making the *shape* of each stress response visible.\n",
    "\n",
    "Four distinct profiles emerge:\n",
    "\n",
    "- **Singer 5** \\u2014 highest absolute HR, steep climb, no recovery between songs. The most pronounced stress response in the study.\n",
    "- **Singer 2** \\u2014 steep initial climb during song 1, partial recovery in the gap, rebound for song 2. Classic performance anxiety arc.\n",
    "- **Singers 1 and 3** \\u2014 moderate, steady climb. Singer 1 shows the most gradual escalation; Singer 3 plateaus earlier.\n",
    "- **Singer 4** \\u2014 flat trajectory near 90 bpm. Modest rise during song 1, return to baseline for song 2. This profile resembles a panelist more than a performer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-reactivity-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "fig_react = go.Figure()\n",
    "for s in singers:\n",
    "    means = []\n",
    "    for phase in perf_phases:\n",
    "        row = phase_sum[(phase_sum['session'] == s) & (phase_sum['subject'] == s) & (phase_sum['phase'] == phase)]\n",
    "        means.append(row['mean_hr'].values[0] if len(row) > 0 else None)\n",
    "    fig_react.add_trace(go.Scatter(\n",
    "        x=[phase_labels[p] for p in perf_phases], y=means,\n",
    "        mode='lines+markers', name=singer_names[s],\n",
    "        line=dict(color=singer_colors[s], width=2), marker=dict(size=10),\n",
    "        hovertemplate='%{y:.1f} bpm<extra>' + singer_names[s] + '</extra>'\n",
    "    ))\n",
    "fig_react.update_layout(\n",
    "    title=dict(text='Singer HR Reactivity Profiles Across Phases', font_size=16),\n",
    "    xaxis_title='Phase', yaxis_title='Mean Heart Rate (bpm)',\n",
    "    template='plotly_white', height=450,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "fig_react.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-norm-text",
   "metadata": {},
   "source": [
    "### Normalized HR Trajectories\n",
    "\n",
    "All five singers' HR traces plotted on a common timeline, each zeroed to their own pre-singing baseline mean. This removes differences in resting HR and shows the *magnitude of change* from baseline.\n",
    "\n",
    "With a 10-second rolling average for readability:\n",
    "\n",
    "- Singers 2 and 5 show the largest sustained elevations (~25\\u201340 bpm above baseline).\n",
    "- Singer 1 shows a moderate, steady rise (~15\\u201330 bpm above baseline).\n",
    "- Singer 3 shows a moderate rise with more variability.\n",
    "- Singer 4 shows the smallest reactivity \\u2014 peaking around +15 bpm during song 1, then *dropping below baseline* during song 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-norm-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "fig_norm = go.Figure()\n",
    "for s in singers:\n",
    "    sess = hr[(hr['session'] == s) & (hr['subject'] == s)].copy().sort_values('elapsed_s')\n",
    "    pre = sess[sess['phase'] == 'pre_singing']\n",
    "    if len(pre) == 0: continue\n",
    "    baseline = pre['hr_bpm'].mean()\n",
    "    sess['hr_norm'] = sess['hr_bpm'] - baseline\n",
    "    sess['hr_smooth'] = sess['hr_norm'].rolling(window=10, center=True, min_periods=1).mean()\n",
    "    fig_norm.add_trace(go.Scatter(\n",
    "        x=sess['elapsed_s'], y=sess['hr_smooth'], mode='lines',\n",
    "        name=singer_names[s], line=dict(color=singer_colors[s], width=2),\n",
    "        hovertemplate='%{y:+.1f} bpm from baseline<extra>' + singer_names[s] + '</extra>'\n",
    "    ))\n",
    "fig_norm.add_hline(y=0, line_dash='dash', line_color='black', line_width=1,\n",
    "                   annotation_text='Baseline', annotation_position='bottom right')\n",
    "fig_norm.update_layout(\n",
    "    title=dict(text='Normalized HR Trajectories (Zeroed to Pre-Singing Baseline)', font_size=16),\n",
    "    xaxis_title='Elapsed Time (seconds)', yaxis_title='HR Change from Baseline (bpm)',\n",
    "    hovermode='x unified', template='plotly_white', height=450,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "fig_norm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part3-header",
   "metadata": {},
   "source": [
    "## Part 3: Same-Song Comparisons\n",
    "\n",
    "Because the assigned piece was the same within each gender group, we can compare singers' HR during the identical musical material. Any differences in HR trajectory during the same song reflect individual anxiety responses rather than differences in musical demands.\n",
    "\n",
    "### Female Singers \\u2014 \\\"If You Knew My Story\\\"\n",
    "\n",
    "During the assigned piece (right panel) \\u2014 the same 32-bar cut \\u2014 Singers 2 and 3 track closely in the 140\\u2013155 bpm range with similar contour, while Singer 4 starts at ~80 bpm and rises slowly to ~99 bpm. The separation between Singer 4 and the other two is even more striking here than during the prepared pieces, because the musical demands are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-female-same-song",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "female_singers = ['S2', 'S3', 'S4']\n",
    "female_colors = {'S2': '#e67e22', 'S3': '#27ae60', 'S4': '#3498db'}\n",
    "\n",
    "fig_female = make_subplots(rows=1, cols=2,\n",
    "    subplot_titles=['Song 1 (Prepared, different pieces)', 'Song 2 (Assigned: \\\"If You Knew My Story\\\")'],\n",
    "    horizontal_spacing=0.1)\n",
    "for phase, col in [('song_1', 1), ('song_2', 2)]:\n",
    "    for s in female_singers:\n",
    "        sess = hr[(hr['session'] == s) & (hr['subject'] == s) & (hr['phase'] == phase)].copy().sort_values('elapsed_s')\n",
    "        if len(sess) == 0: continue\n",
    "        sess['song_time'] = sess['elapsed_s'] - sess['elapsed_s'].min()\n",
    "        fig_female.add_trace(go.Scatter(\n",
    "            x=sess['song_time'], y=sess['hr_bpm'], mode='lines',\n",
    "            name=singer_names[s], line=dict(color=female_colors[s], width=2),\n",
    "            legendgroup=s, showlegend=(col == 1),\n",
    "            hovertemplate='%{y} bpm<extra>' + singer_names[s] + '</extra>'\n",
    "        ), row=1, col=col)\n",
    "fig_female.update_layout(\n",
    "    title=dict(text='Female Singers \\u2014 Prepared vs. Assigned Song', font_size=16),\n",
    "    hovermode='x unified', template='plotly_white', height=400,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.08, xanchor='right', x=1),\n",
    "    margin=dict(t=100, b=60)\n",
    ")\n",
    "fig_female.update_xaxes(title_text='Time from Song Onset (s)')\n",
    "fig_female.update_yaxes(title_text='Heart Rate (bpm)', col=1)\n",
    "fig_female.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-female-panelist-text",
   "metadata": {},
   "source": [
    "Each female singer during \\\"If You Knew My Story\\\" with all three panelists overlaid:\n",
    "\n",
    "- **Singer 2:** Sustained at 140\\u2013155 bpm. All three panelists hold flat below, with Panelist 2 running lowest (~57 bpm). The singer sits 40\\u201380+ bpm above the panelist range.\n",
    "- **Singer 3:** Similar profile to Singer 2. Panelist traces are stable and well below.\n",
    "- **Singer 4:** Starts at ~80 bpm \\u2014 *below Panelist 1* (~98 bpm) and near Panelist 3 (~92 bpm). Only Panelist 2 (~56 bpm) is consistently below her. This is the only session where the singer's HR is intertwined with the panelists' during active singing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-female-panelist-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "fig_fp = make_subplots(rows=1, cols=3,\n",
    "    subplot_titles=['Singer 2 (F)', 'Singer 3 (F)', 'Singer 4 (F)'],\n",
    "    horizontal_spacing=0.08)\n",
    "for col_idx, s in enumerate(female_singers, 1):\n",
    "    singer_s2 = hr[(hr['session'] == s) & (hr['subject'] == s) & (hr['phase'] == 'song_2')].copy().sort_values('elapsed_s')\n",
    "    if len(singer_s2) == 0: continue\n",
    "    t0 = singer_s2['elapsed_s'].min()\n",
    "    singer_s2['song_time'] = singer_s2['elapsed_s'] - t0\n",
    "    fig_fp.add_trace(go.Scatter(\n",
    "        x=singer_s2['song_time'], y=singer_s2['hr_bpm'], mode='lines',\n",
    "        name=singer_names[s], line=dict(color=female_colors[s], width=2),\n",
    "        legendgroup='singer_' + s, showlegend=(col_idx == 1),\n",
    "        hovertemplate='%{y} bpm<extra>' + singer_names[s] + '</extra>'\n",
    "    ), row=1, col=col_idx)\n",
    "    for pan in panelists:\n",
    "        pan_data = hr[(hr['session'] == s) & (hr['subject'] == pan) & (hr['phase'] == 'song_2')].copy().sort_values('elapsed_s')\n",
    "        if len(pan_data) == 0: continue\n",
    "        pan_data['song_time'] = pan_data['elapsed_s'] - t0\n",
    "        fig_fp.add_trace(go.Scatter(\n",
    "            x=pan_data['song_time'], y=pan_data['hr_bpm'], mode='lines',\n",
    "            name=panelist_names[pan], line=dict(color=trace_colors[pan], width=1.5, dash='dash'),\n",
    "            legendgroup=pan, showlegend=(col_idx == 1),\n",
    "            hovertemplate='%{y} bpm<extra>' + panelist_names[pan] + '</extra>'\n",
    "        ), row=1, col=col_idx)\n",
    "fig_fp.update_layout(\n",
    "    title=dict(text='Female Singers + All Panelists During \\\"If You Knew My Story\\\"', font_size=16),\n",
    "    hovermode='x unified', template='plotly_white', height=400,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.08, xanchor='right', x=1),\n",
    "    margin=dict(t=100, b=60)\n",
    ")\n",
    "fig_fp.update_xaxes(title_text='Time from Song Onset (s)')\n",
    "fig_fp.update_yaxes(title_text='Heart Rate (bpm)', col=1)\n",
    "fig_fp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-male-text",
   "metadata": {},
   "source": [
    "### Male Singers \\u2014 \\\"Shiksa Goddess\\\"\n",
    "\n",
    "During the assigned piece (right panel), Singer 5 starts at ~166 bpm and climbs to ~180 bpm. Singer 1 starts at ~149 bpm and rises gently to ~158 bpm. The ~15\\u201320 bpm gap between them is consistent, suggesting a stable difference in stress reactivity rather than a response to a specific musical moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-male-same-song",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "male_singers = ['S1', 'S5']\n",
    "male_colors = {'S1': '#e74c3c', 'S5': '#8e44ad'}\n",
    "fig_male = make_subplots(rows=1, cols=2,\n",
    "    subplot_titles=['Song 1 (Prepared, different pieces)', 'Song 2 (Assigned: \\\"Shiksa Goddess\\\")'],\n",
    "    horizontal_spacing=0.1)\n",
    "for phase, col in [('song_1', 1), ('song_2', 2)]:\n",
    "    for s in male_singers:\n",
    "        sess = hr[(hr['session'] == s) & (hr['subject'] == s) & (hr['phase'] == phase)].copy().sort_values('elapsed_s')\n",
    "        if len(sess) == 0: continue\n",
    "        sess['song_time'] = sess['elapsed_s'] - sess['elapsed_s'].min()\n",
    "        fig_male.add_trace(go.Scatter(\n",
    "            x=sess['song_time'], y=sess['hr_bpm'], mode='lines',\n",
    "            name=singer_names[s], line=dict(color=male_colors[s], width=2),\n",
    "            legendgroup=s, showlegend=(col == 1),\n",
    "            hovertemplate='%{y} bpm<extra>' + singer_names[s] + '</extra>'\n",
    "        ), row=1, col=col)\n",
    "fig_male.update_layout(\n",
    "    title=dict(text='Male Singers \\u2014 Prepared vs. Assigned Song', font_size=16),\n",
    "    hovermode='x unified', template='plotly_white', height=400,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.08, xanchor='right', x=1),\n",
    "    margin=dict(t=100, b=60)\n",
    ")\n",
    "fig_male.update_xaxes(title_text='Time from Song Onset (s)')\n",
    "fig_male.update_yaxes(title_text='Heart Rate (bpm)', col=1)\n",
    "fig_male.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-male-panelist-text",
   "metadata": {},
   "source": [
    "Each male singer during \\\"Shiksa Goddess\\\" with all three panelists:\n",
    "\n",
    "- **Singer 1:** Flat trace at ~150\\u2013158 bpm. All three panelists well below. The gap between singer and 3-panelist mean (~70 bpm) is stable throughout.\n",
    "- **Singer 5:** Climbing trace from ~166 to ~180 bpm. The gap *widens* over the course of the song \\u2014 panelists hold flat or decrease while Singer 5 continues climbing. Panelist 3 shows the clearest antiphase pattern (HR decreasing as singer's increases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-male-panelist-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "fig_mp = make_subplots(rows=1, cols=2,\n",
    "    subplot_titles=['Singer 1 (M)', 'Singer 5 (M)'],\n",
    "    horizontal_spacing=0.1)\n",
    "for col_idx, s in enumerate(male_singers, 1):\n",
    "    singer_s2 = hr[(hr['session'] == s) & (hr['subject'] == s) & (hr['phase'] == 'song_2')].copy().sort_values('elapsed_s')\n",
    "    if len(singer_s2) == 0: continue\n",
    "    t0 = singer_s2['elapsed_s'].min()\n",
    "    singer_s2['song_time'] = singer_s2['elapsed_s'] - t0\n",
    "    fig_mp.add_trace(go.Scatter(\n",
    "        x=singer_s2['song_time'], y=singer_s2['hr_bpm'], mode='lines',\n",
    "        name=singer_names[s], line=dict(color=male_colors[s], width=2),\n",
    "        legendgroup='singer_' + s, showlegend=(col_idx == 1),\n",
    "        hovertemplate='%{y} bpm<extra>' + singer_names[s] + '</extra>'\n",
    "    ), row=1, col=col_idx)\n",
    "    for pan in panelists:\n",
    "        pan_data = hr[(hr['session'] == s) & (hr['subject'] == pan) & (hr['phase'] == 'song_2')].copy().sort_values('elapsed_s')\n",
    "        if len(pan_data) == 0: continue\n",
    "        pan_data['song_time'] = pan_data['elapsed_s'] - t0\n",
    "        fig_mp.add_trace(go.Scatter(\n",
    "            x=pan_data['song_time'], y=pan_data['hr_bpm'], mode='lines',\n",
    "            name=panelist_names[pan], line=dict(color=trace_colors[pan], width=1.5, dash='dash'),\n",
    "            legendgroup=pan, showlegend=(col_idx == 1),\n",
    "            hovertemplate='%{y} bpm<extra>' + panelist_names[pan] + '</extra>'\n",
    "        ), row=1, col=col_idx)\n",
    "fig_mp.update_layout(\n",
    "    title=dict(text='Male Singers + All Panelists During \\\"Shiksa Goddess\\\"', font_size=16),\n",
    "    hovermode='x unified', template='plotly_white', height=400,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.08, xanchor='right', x=1),\n",
    "    margin=dict(t=100, b=60)\n",
    ")\n",
    "fig_mp.update_xaxes(title_text='Time from Song Onset (s)')\n",
    "fig_mp.update_yaxes(title_text='Heart Rate (bpm)', col=1)\n",
    "fig_mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part4-header",
   "metadata": {},
   "source": [
    "## Part 4: Interpretive Notes\n",
    "\n",
    "### The Singer 4 \\u2013 Panelist 3 Relationship\n",
    "\n",
    "Singer 4 is a student of Panelist 3 \\u2014 they have a pre-existing teacher-student relationship. This is an important interpretive lens for several findings:\n",
    "\n",
    "1. **Singer 4's low HR** is consistent with reduced evaluative threat. Performing for one's own teacher \\u2014 someone who knows your voice, has heard you at your worst, and is invested in your success \\u2014 may reduce the sense that resources are insufficient to meet demands (the \\\"threat\\\" state in the biopsychosocial model; Guyon et al., 2020).\n",
    "\n",
    "2. **The HR convergence** between Singer 4 and Panelist 3 is consistent with what Coutinho et al. (2021) describe in established relationships. In their study of romantic couples, partners in close relationships showed distinctive physiological synchrony patterns \\u2014 including in-phase HR coupling. While Singer 4 and Panelist 3 are not romantic partners, the teacher-student bond represents the closest interpersonal relationship of any singer-panelist dyad in this study, and it produces the most convergent physiological profile.\n",
    "\n",
    "3. **All three panelists show elevated variability** during Singer 4's session. Panelist 3's HR is the most variable of any session (sd=8.1 during the inter-song gap). Panelist 1 also shows its highest variability here (sd=5.8, spiking to ~113 bpm). Even Panelist 2, typically the most stable, shows slightly more variation. This suggests Session 4 was physiologically distinctive for the entire panel.\n",
    "\n",
    "**For the thesis:** This dyad should be discussed as both a limitation (the teacher-student relationship is a confound that makes Singer 4's data non-equivalent to the other singers in terms of evaluative stress) and as a case study in co-regulation (the strongest evidence of physiological coupling in the dataset occurs in the dyad with the deepest relational history)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-anticipatory",
   "metadata": {},
   "source": [
    "### Anticipatory Anxiety\n",
    "\n",
    "Four of five singers show pre-singing HR values of 126\\u2013143 bpm \\u2014 substantially elevated above typical resting heart rate (60\\u201380 bpm for young adults). This is consistent with Vellers et al. (2017), who identified the pre-performance anticipatory period as the most sensitive window for detecting audition stress. The singers are already in a state of sympathetic activation before they begin singing. Singer 4, again, is the exception at ~91 bpm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-panelist-anticipatory",
   "metadata": {},
   "source": [
    "### Panelist Anticipatory Activation\n",
    "\n",
    "The singer anticipatory anxiety finding has a counterpart on the panelist side. All three panelists \\u2014 seated throughout \\u2014 show HR ramp-ups in the final seconds of the inter-song gap before song 2 begins. Because the panelists did not stand, shift position, or move during the auditions, these HR changes cannot be attributed to postural artifacts. They reflect genuine autonomic activation \\u2014 the evaluative experience of preparing to hear the next piece.\n",
    "\n",
    "Panelist 3 shows the most consistent pattern (anticipatory activation in 4 of 5 sessions), with Session 4 (her own student) producing the largest ramp (+17.7 bpm). Panelist 1 shows activation in 3 of 5 sessions. Panelist 2, with the lowest overall HR, shows modest changes that are harder to distinguish from baseline fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-panelist-anticipatory-fig",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "antic_rows = []\n",
    "for s in singers:\n",
    "    gap_data = hr[(hr['session'] == s) & (hr['phase'] == 'inter_song_gap')]\n",
    "    for pan in panelists:\n",
    "        pan_gap = gap_data[gap_data['subject'] == pan].sort_values('elapsed_s')\n",
    "        if len(pan_gap) < 10: continue\n",
    "        first_5 = pan_gap.head(5)['hr_bpm'].mean()\n",
    "        last_5 = pan_gap.tail(5)['hr_bpm'].mean()\n",
    "        antic_rows.append({'session': s, 'panelist': pan, 'change_bpm': last_5 - first_5})\n",
    "antic_df = pd.DataFrame(antic_rows)\n",
    "\n",
    "fig_antic = go.Figure()\n",
    "for pan in panelists:\n",
    "    pdf = antic_df[antic_df['panelist'] == pan]\n",
    "    fig_antic.add_trace(go.Bar(\n",
    "        name=panelist_names[pan],\n",
    "        x=['Session ' + s[-1] for s in pdf['session']],\n",
    "        y=pdf['change_bpm'], marker_color=trace_colors[pan],\n",
    "        hovertemplate='%{y:+.1f} bpm<extra>' + panelist_names[pan] + '</extra>'\n",
    "    ))\n",
    "fig_antic.add_hline(y=0, line_dash='dash', line_color='black', line_width=1)\n",
    "fig_antic.update_layout(\n",
    "    title=dict(text='Panelist Anticipatory Activation (Inter-Song Gap: Last 5s vs. First 5s)', font_size=14),\n",
    "    xaxis_title='Session', yaxis_title='HR Change (bpm)',\n",
    "    barmode='group', template='plotly_white', height=400,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "fig_antic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-prepared-vs-assigned",
   "metadata": {},
   "source": [
    "### Prepared vs. Assigned Song\n",
    "\n",
    "The data does not show a simple pattern of \\\"assigned piece = more anxiety.\\\" Some singers (1, 3, 5) show higher HR during song 2 (assigned), but Singer 2 shows *lower* HR during song 2 than song 1. This may reflect:\n",
    "\n",
    "- Fatigue or habituation (HR naturally declining after sustained high effort)\n",
    "- The assigned piece being shorter and less demanding than some prepared pieces\n",
    "- Individual differences in how novelty vs. familiarity affects stress\n",
    "\n",
    "The comparison is also confounded by order \\u2014 song 2 always follows song 1, so any \\\"assigned piece\\\" effect is inseparable from a \\\"second performance\\\" effect. This should be acknowledged as a design limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-kmpai-header",
   "metadata": {},
   "source": [
    "## K-MPAI and MAAQ Pre-Survey Results\n",
    "\n",
    "The K-MPAI was administered to all BoCo BFA/MM voice students as a pre-screening survey. The 5 study participants were drawn from this broader pool of 26 respondents. Scoring follows Kenny (2009): 40 items on a 0\\u20136 scale with 8 reverse-coded positive items (1, 2, 9, 17, 23, 33, 35, 37), range 0\\u2013240, clinical threshold \\u2265105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-kmpai-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "pop = pd.read_csv('data/singer_population_kmpai_maaq.csv')\n",
    "singers_pre = pd.read_csv('data/singer_pre_survey.csv')\n",
    "\n",
    "fig_kmpai = go.Figure()\n",
    "fig_kmpai.add_trace(go.Histogram(\n",
    "    x=pop['kmpai_total'], nbinsx=15,\n",
    "    name='All BoCo Respondents (n=26)',\n",
    "    marker_color='rgba(158, 158, 158, 0.6)',\n",
    "    hovertemplate='K-MPAI: %{x}<br>Count: %{y}<extra></extra>'\n",
    "))\n",
    "for _, row in singers_pre.iterrows():\n",
    "    s = row['singer']\n",
    "    fig_kmpai.add_vline(\n",
    "        x=row['kmpai_total'], line_dash='solid', line_color=singer_colors[s], line_width=2,\n",
    "        annotation_text=singer_names[s], annotation_position='top',\n",
    "        annotation_font_size=11, annotation_font_color=singer_colors[s]\n",
    "    )\n",
    "fig_kmpai.add_vline(\n",
    "    x=105, line_dash='dash', line_color='red', line_width=1.5,\n",
    "    annotation_text='Clinical threshold (105)', annotation_position='bottom right',\n",
    "    annotation_font_size=10, annotation_font_color='red'\n",
    ")\n",
    "fig_kmpai.update_layout(\n",
    "    title=dict(text='K-MPAI Score Distribution \\u2014 BoCo Singer Population', font_size=16),\n",
    "    xaxis_title='K-MPAI Total Score (0\\u2013240)', yaxis_title='Count',\n",
    "    template='plotly_white', height=400, showlegend=True,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "fig_kmpai.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-kmpai-pop-text",
   "metadata": {},
   "source": [
    "**Population (26 BoCo singer respondents):**\n",
    "\n",
    "- Mean K-MPAI: 124.1 (SD 31.6), Median: 124.0, Range: 64\\u2013185\n",
    "- 73% (19/26) score \\u2265105 (clinically significant MPA)\n",
    "- This is a high-anxiety population, consistent with conservatory performance culture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-kmpai-scatter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "peak_hrs = []\n",
    "for _, row in singers_pre.iterrows():\n",
    "    s = row['singer']\n",
    "    s1r = phase_sum[(phase_sum['session'] == s) & (phase_sum['subject'] == s) & (phase_sum['phase'] == 'song_1')]\n",
    "    s2r = phase_sum[(phase_sum['session'] == s) & (phase_sum['subject'] == s) & (phase_sum['phase'] == 'song_2')]\n",
    "    peak_hrs.append(max(\n",
    "        s1r['mean_hr'].values[0] if len(s1r) > 0 else 0,\n",
    "        s2r['mean_hr'].values[0] if len(s2r) > 0 else 0\n",
    "    ))\n",
    "singers_pre_plot = singers_pre.copy()\n",
    "singers_pre_plot['peak_hr'] = peak_hrs\n",
    "\n",
    "fig_scatter = go.Figure()\n",
    "for _, row in singers_pre_plot.iterrows():\n",
    "    s = row['singer']\n",
    "    fig_scatter.add_trace(go.Scatter(\n",
    "        x=[row['kmpai_total']], y=[row['peak_hr']],\n",
    "        mode='markers+text', name=singer_names[s],\n",
    "        marker=dict(color=singer_colors[s], size=14),\n",
    "        text=[singer_names[s]], textposition='top center',\n",
    "        hovertemplate='K-MPAI: %{x}<br>Peak HR: %{y:.0f} bpm<extra>' + singer_names[s] + '</extra>'\n",
    "    ))\n",
    "fig_scatter.update_layout(\n",
    "    title=dict(text='K-MPAI Score vs. Peak Performance HR', font_size=16),\n",
    "    xaxis_title='K-MPAI Total Score', yaxis_title='Peak Mean HR During Performance (bpm)',\n",
    "    template='plotly_white', height=400, showlegend=False,\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "fig_scatter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-kmpai-participants",
   "metadata": {},
   "source": [
    "**Study participants:**\n",
    "\n",
    "| Singer | K-MPAI | Clinical? | MAAQ Flexibility | Notes |\n",
    "|--------|--------|-----------|-----------------|-------|\n",
    "| S1 (M) | 126 | Yes | 31 | Near population mean |\n",
    "| S2 (F) | 111 | Yes | 35 (highest) | Lowest anxiety, highest flexibility |\n",
    "| S3 (F) | 144 | Yes | 26 | Above population mean |\n",
    "| S4 (F) | 159 | Yes | 21 | High anxiety despite lowest HR |\n",
    "| S5 (M) | 174 | Yes | 17 (lowest) | Highest anxiety, lowest flexibility |\n",
    "\n",
    "All 5 singers score above the clinical threshold \\u2014 not surprising given they self-selected for a study on performance anxiety. The rank ordering is notable: **Singer 5 (highest K-MPAI, 174) also shows the highest sustained HR in the study, while Singer 2 (lowest K-MPAI, 111) shows the steepest HR ramp-up but also the most recovery between songs.** Singer 4 (K-MPAI 159 \\u2014 second highest) is the most interesting case: high self-reported anxiety with the *lowest* physiological response, suggesting that the teacher-student relationship with Panelist 3 may buffer the somatic expression of trait anxiety.\n",
    "\n",
    "**Faculty panelists:**\n",
    "\n",
    "| Panelist | K-MPAI | Clinical? | MAAQ Flexibility | Mean HR (seated) |\n",
    "|----------|--------|-----------|-----------------|------------------|\n",
    "| Panelist 1 | 109 (2 items missing) | Yes | 24 | ~101 bpm |\n",
    "| Panelist 2 | 102 | No | 33 | ~58 bpm |\n",
    "| Panelist 3 | 169 | Yes | 32 | ~85 bpm |\n",
    "\n",
    "Panelist 3's K-MPAI (169) is notably high \\u2014 higher than any study participant except Singer 5. For a panelist whose own performance anxiety is elevated, evaluating singers (especially her own student, Singer 4) may carry additional physiological weight. Panelist 2 falls just below the clinical threshold at 102 and shows the lowest HR of anyone in the study \\u2014 essentially resting heart rate while seated. The K-MPAI ranking on the faculty side (F3 > F1 > F2) does not map directly to their HR ranking (F1 > F3 > F2), but Panelist 2 being the calmest on both measures is consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-scoring-note",
   "metadata": {},
   "source": [
    "#### K-MPAI Scoring Note\n",
    "\n",
    "The Qualtrics-generated SC0 score differs from our computed score by a constant of +40 across all 26 respondents (verified: identical SDs, perfect rank correlation). Qualtrics scores the K-MPAI on a 1\\u20137 internal scale, while Kenny (2009) specifies 0\\u20136. Both apply the same reverse coding on the same 8 items \\u2014 the only difference is a +1 shift per item across all 40 items (40 \\u00d7 1 = 40). We use the published 0\\u20136 convention. The Qualtrics threshold equivalent of \\u2265105 is \\u2265145."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Singer | Pre-Singing HR | Song 1 HR | Song 2 HR | Reactivity (Song 1 \\u2212 Baseline) | Activation Gap (Song 2) | K-MPAI | Notes |\n",
    "|--------|---------------|-----------|-----------|-------------------------------|------------------------|--------|-------|\n",
    "| S1 (M) | 128 | 144 | 154 | +16 | +70 | 126 | Steady climber; flattest assigned-song trace |\n",
    "| S2 (F) | 128 | 160 | 147 | +32 | +66 | 111 | Steepest ramp-up; HR *drops* for song 2 |\n",
    "| S3 (F) | 126 | 150 | 152 | +24 | +70 | 144 | Moderate, steady; similar to S2 during assigned song |\n",
    "| S4 (F) | 91 | 106 | 90 | +15 | +8 | 159 | Outlier \\u2014 pre-existing relationship with F3; HR near panelist range |\n",
    "| S5 (M) | 143 | 167 | 170 | +24 | +91 | 174 | Highest absolute HR; no recovery between songs |\n",
    "\n",
    "*All values are mean HR in bpm. Activation gap = singer mean HR minus mean of all three panelists during song 2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-pending",
   "metadata": {},
   "source": [
    "### Data Pending\n",
    "\n",
    "- **Post-survey \\u00d7 HR correlation** \\u2014 the processed post-survey data has not yet been correlated with HR measures.\n",
    "- **K-MPAI \\u00d7 HR correlation** \\u2014 the association between trait anxiety scores and physiological reactivity is ready to be tested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}